{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting wages with a Keras neural network\n",
    "\n",
    "In this analysis I'll build a basic nueral network model in Keras. One of the goals with this analysis is to quickly be able to run more complex neural network models on larger datasets. Speaking of datasets, I'm using one that should allow for the prediction of an individuals hourly wages given characteristics like their industry, education and level of experience. Unfortunately, this dataset is (seemingly) no longer hosted anywhere notable, so I'll make it available on my [personal github page](https://github.com/brukeg/notebooks/tree/master/datasets/predicting-wages.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and explore the data set\n",
    "df = pd.read_csv('datasets/hourly_wages.csv')\n",
    "\n",
    "\n",
    "# create arrays for the features and target variable\n",
    "target = df.wage_per_hour.values\n",
    "predictors = df.drop('wage_per_hour', axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started \n",
    "<p>To start off with, I'll take a skeleton of a neural network and add a hidden layer and an output layer. As refresher, a nueral network contains an input layer, at least 1 hidden layer, and an output layer. I'll then fit that model and see Keras do the optimization so the model continually gets better.</p>\n",
    "\n",
    "<p><img src=\"datasets/Hidden_Layer_print.png\" width=\"50%\" align=\"center\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer (input)\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer (hidden)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling and Fitting the Model\n",
    "I'm now going to compile the model I specified above. To compile the model, I'll simply need to specify the optimizer and loss function to use. The Adam optimizer is an excellent first choice, and MSE will work just fine for my purposes as a loss function. You can do further reading about it and other keras optimizers [here](https://keras.io/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer.\n",
    "\n",
    "Finally, I'll fit the model using the `.fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "373/373 [==============================] - 1s 3ms/step - loss: 30.7995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a342ef650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.642925   5.0396843  6.522493   9.660091   6.7229195  6.852784\n",
      " 10.493897   5.3469477  7.998204   7.487485   8.494655   6.9070754\n",
      "  7.70672    7.625542   7.20399    6.53131    7.934996  13.16728\n",
      "  8.4557    10.16424    8.951924  14.493992   7.0996046  8.762305\n",
      "  4.39365    9.08064   10.469973  11.224567  12.831081  12.685733\n",
      "  6.773531  12.028591   7.1843157  9.966084  13.454934   5.0752106\n",
      "  8.015115   8.928014   7.341394   7.520835  12.755751   8.796549\n",
      "  8.41497   12.734032  12.572275  14.453107   6.8306456  9.7016735\n",
      "  6.602378   5.711293   8.467966  13.168735  11.36424   11.987953\n",
      "  7.6612186  4.8784084  9.672422   7.919685  10.447189   6.9081707\n",
      "  6.4492254 10.559987   7.3353686  9.048932   6.284211   8.777804\n",
      " 10.559987   8.486797  10.58222    6.489592   4.7867994  8.265329\n",
      " 13.246117   4.7984037  5.220437  13.383447  12.034864   4.6860037\n",
      " 13.649389   5.473402  13.9430685  5.055064   8.58242    9.447361\n",
      "  6.561168   6.8306456  6.1303015  7.27864    7.70672    5.9459987\n",
      "  6.0304613  9.562288   8.444975   6.3090525  8.18158   13.168108\n",
      "  6.880479   7.5962124 10.690374   9.55282    8.545347   7.2263412\n",
      "  7.115597   8.326212  11.386264  13.630654   6.4014897  9.762226\n",
      "  9.426622   7.7779117 13.440551   4.2905364  5.7362356 12.336844\n",
      "  8.049387   6.0304613 13.302926   6.3184843  8.512539  10.017645\n",
      " 11.074284   6.544257  10.702049   5.6890144  6.274026   8.267522\n",
      " 14.313249   6.880479  11.812214   4.412385   7.951746  12.694746\n",
      " 11.733061  10.0127735  6.8713827 12.231024   9.413368  12.259714\n",
      " 10.981382   9.21323    7.944903   5.1307745  4.8248873  5.8231826\n",
      "  9.391203  13.007402   4.545641   8.20475   15.394347   5.1185665\n",
      "  9.2924185 12.336844  10.778943   7.6088014 14.522905  14.978607\n",
      "  6.676735  12.142324  13.4828    14.458302   7.4273696]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate predicted wages\n",
    "predicted_prob_true = predictions[:,0]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)\n",
    "\n",
    "# print the differnce between known wages and our predicted ones\n",
    "#print(predicted_prob_true-target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FROM TITANIC EXERCISE\"\"\"\n",
    "\n",
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FROM TITANIC EXERCISE\"\"\"\n",
    "\n",
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy' )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
