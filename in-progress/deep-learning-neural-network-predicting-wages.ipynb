{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting wages with a Keras neural network\n",
    "\n",
    "In this analysis I'll build a nueral network model using the Keras interface to the TensorFlow deep learning library. One of the goals with this analysis is to quickly be able to run more complex neural network models on larger datasets. Speaking of datasets, I'm using one that should allow for the prediction of an individuals hourly wages given characteristics like their industry, education and level of experience. Unfortunately, this dataset is (seemingly) no longer hosted anywhere notable, so I'll make it available on my [personal github page](https://github.com/brukeg/notebooks/tree/master/datasets/predicting-wages.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('datasets/hourly_wages.csv')\n",
    "\n",
    "# Create arrays for the features (predictors) and target variable\n",
    "target = df.wage_per_hour.values\n",
    "predictors = df.drop('wage_per_hour', axis=1).values\n",
    "\n",
    "# Create training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
    "                                                    target, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Explore the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started \n",
    "<p>To start off with, I'll take a skeleton of a neural network and add hidden layers and an output layer. As refresher, a nueral network contains an input layer, at least 1 hidden layer, and an output layer. I'll then fit that model and let Keras do the optimization so the model continually gets better.</p>\n",
    "\n",
    "<p><img src=\"datasets/Hidden_Layer_print.png\" width=\"50%\" align=\"center\"></p>\n",
    "\n",
    "A Keras work flow has four steps. First you specify the architecture like how many layers you want, how many nodes in each layer, what activation function to use, etc. Next you compile the model, this specifies the loss function and some details about how optimization should work. Third, you fit the model, which is the cycle of backpropagation that optimizes models weights with the data. Finally, you use the model to make predictions about the data. I'll demonstrate this four step process below. In each cell, I'll often re-use code from the previous cell just to show how simple this can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the architecture:\n",
    "\n",
    "# Save the number of columns in predictors as the number of input nodes in the model\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Instanstiate a sequential NN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer specifying the input shape (nodes in the model)\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling and Fitting the Model\n",
    "I'm now going to compile the model I specified above; this sets up the model to do backpropagation over an optimizer. To compile the model, I'll simply need to specify two neccessary arguments. Namely, the optimizer and loss function to use. The Adam optimizer is an excellent first choice, and MSE will work just fine for my purposes as a loss function. You can do further reading about it and other keras optimizers [here](https://keras.io/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer.\n",
    "\n",
    "In the following cell I'll fit the model using the `.fit()` method. The fit step is where backpropagtion and gradient descent are applied to update the weights between each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Specify the model just as before\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "373/373 [==============================] - 1s 3ms/step - loss: 48.7523\n",
      "Epoch 2/10\n",
      "373/373 [==============================] - 0s 283us/step - loss: 33.5594\n",
      "Epoch 3/10\n",
      "373/373 [==============================] - 0s 212us/step - loss: 26.8189\n",
      "Epoch 4/10\n",
      "373/373 [==============================] - 0s 225us/step - loss: 23.4936\n",
      "Epoch 5/10\n",
      "373/373 [==============================] - 0s 170us/step - loss: 22.2892\n",
      "Epoch 6/10\n",
      "373/373 [==============================] - 0s 165us/step - loss: 21.9430\n",
      "Epoch 7/10\n",
      "373/373 [==============================] - 0s 146us/step - loss: 21.6123\n",
      "Epoch 8/10\n",
      "373/373 [==============================] - 0s 151us/step - loss: 21.3651\n",
      "Epoch 9/10\n",
      "373/373 [==============================] - 0s 138us/step - loss: 21.2729\n",
      "Epoch 10/10\n",
      "373/373 [==============================] - 0s 119us/step - loss: 21.5565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3c295250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model just as before\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model just as before\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model specifying the desired number of epochs (iterations over the entire X and y data provided)\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.745859   7.433459   8.60953    8.851855   8.920377   8.124661\n",
      "  8.034364   7.4847617 10.203319   8.024747   9.201648  10.27475\n",
      "  8.332324   8.541685   7.6393     8.155673  10.479332   9.415298\n",
      " 11.145835   6.7195163  8.82191    9.374919   8.291409   8.046743\n",
      "  6.9928975 10.752646  11.401799  11.09357    7.798319   9.605726\n",
      "  9.470518  10.133234   9.4612055 11.071573  12.550696   7.165855\n",
      " 10.214699   8.345549   8.485641  10.776885   9.597451   8.694691\n",
      "  9.450538  10.017768   7.443108   8.281192   8.161546   8.344739\n",
      "  8.952694   6.2367454  9.017238   9.313125   8.7930975  8.5409155\n",
      "  8.403498   6.9806027  8.778039   7.5068192  9.972711   7.6570725\n",
      "  8.29796    8.568919   7.583703  11.379802   7.841994   8.596922\n",
      "  8.568919   7.5881543  8.417796   8.3093405  8.334565   8.146658\n",
      "  9.6117735  7.26537    7.523249  10.596723  11.230952   7.027748\n",
      "  7.8493376  8.798048   9.019937   7.340445   6.529385   9.118409\n",
      "  8.074105   8.161546   8.003276  10.497347   8.332324   8.828879\n",
      "  7.366823   9.603544   8.021453   7.5989323  8.961194  10.049636\n",
      "  9.300947   9.492582  10.02876   11.710027  10.783609   7.971343\n",
      "  9.583655  10.000716   9.229041  11.968291   7.0686207 10.250186\n",
      "  8.795811   9.737749  10.054895   6.884626   7.3206105  9.073322\n",
      "  9.87869    7.366823   9.289225   7.505984   7.9906983  9.353507\n",
      "  8.536016   8.062724  10.166947   7.5636725  9.901635   8.00847\n",
      " 12.774875   9.300947   9.180513   6.86164    8.717769   8.217557\n",
      "  7.863516   8.32961    9.506928  10.810634  10.670503   9.580439\n",
      " 11.037527   9.400537   8.526557   6.9674206  6.7816553  9.246609\n",
      "  7.8123326  7.7076983  7.86466    8.773814  11.891759   7.9138923\n",
      " 11.760957   9.073322   7.4950185  8.849104   8.919858   9.656911\n",
      "  8.35052    9.017276   9.40959    8.437375   7.652956 ]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,165\n",
      "Trainable params: 2,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate predicted wages\n",
    "predicted_prob_true = predictions[:,0]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)\n",
    "\n",
    "# print the differnce between known wages and our predicted ones\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Optimization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "\n",
    "def nn_model(epochs):\n",
    "    \"\"\"create the NN model\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile then return the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -26.20 (5.34) MSE\n"
     ]
    }
   ],
   "source": [
    "# Import neccessary modules\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "steps = [('standardize', StandardScaler()),\n",
    "         ('model', KerasRegressor(build_fn=nn_model, \n",
    "                                  epochs=10,\n",
    "                                  batch_size=5, \n",
    "                                  verbose=0))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "scaled_predictions = pipeline.predict(X_test)\n",
    "\n",
    "kfold = KFold(n_splits=2, random_state=7)\n",
    "results = cross_val_score(pipeline, X_test, y_test, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
